#!/usr/bin/env python3
"""
Debug script Ä‘á»ƒ kiá»ƒm tra táº¡i sao tá»· lá»‡ thÃ nh cÃ´ng tháº¥p
"""

import json
import requests
from bs4 import BeautifulSoup
import random

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
]

def test_url(url: str):
    """Test má»™t URL Ä‘á»ƒ xem táº¡i sao khÃ´ng láº¥y Ä‘Æ°á»£c product name"""
    print(f"\nğŸ” Testing URL: {url}")
    
    try:
        resp = requests.get(url, headers={"User-Agent": random.choice(USER_AGENTS)}, 
                          timeout=10, allow_redirects=True)
        print(f"Status Code: {resp.status_code}")
        print(f"Final URL: {resp.url}")
        print(f"Content Length: {len(resp.text)}")
        
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            
            # Test cÃ¡c selector
            selectors = [
                "h1.page-title span.base",
                "h1.product-title", 
                "h1.product-name",
                "h1",
                ".product-title",
                ".product-name", 
                ".page-title",
                "title"
            ]
            
            found_selectors = []
            for sel in selectors:
                el = soup.select_one(sel)
                if el:
                    text = el.get_text(strip=True)
                    if text and len(text) > 3:
                        found_selectors.append(f"{sel}: '{text}'")
            
            if found_selectors:
                print("âœ… Found selectors:")
                for sel in found_selectors:
                    print(f"  - {sel}")
            else:
                print("âŒ No product name found")
                print("Available h1 tags:")
                for h1 in soup.find_all('h1'):
                    print(f"  - {h1.get_text(strip=True)}")
                print("Available title tag:")
                title = soup.find('title')
                if title:
                    print(f"  - {title.get_text(strip=True)}")
        else:
            print(f"âŒ HTTP Error: {resp.status_code}")
            
    except Exception as e:
        print(f"âŒ Error: {e}")

def main():
    print("ğŸ› Debug Crawler - Testing sample URLs")
    
    # Äá»c má»™t vÃ i URLs tá»« file Ä‘á»ƒ test
    try:
        with open("product_urls.jsonl", "r", encoding="utf-8") as f:
            urls_to_test = []
            for i, line in enumerate(f):
                if i >= 10:  # Test 10 URLs Ä‘áº§u
                    break
                try:
                    data = json.loads(line.strip())
                    urls_to_test.append(data['url'])
                except:
                    continue
            
            print(f"ğŸ“Š Testing {len(urls_to_test)} sample URLs...")
            
            for url in urls_to_test:
                test_url(url)
                
    except FileNotFoundError:
        print("âŒ File product_urls.jsonl not found. Run data_filter.py first.")
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main()

